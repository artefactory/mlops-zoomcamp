{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_january = pd.read_parquet('.data/.fhv_tripdata_2021-01.parquet')\n",
    "dataset_february = pd.read_parquet('.data/.fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Read the data for January. How many records are there? -> 1154112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1154112, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_january.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What's the average trip duration in January? -> 19 min 10 s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_january['trip_duration'] = dataset_january['dropOff_datetime'] - dataset_january['pickup_datetime'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:19:10.033445627')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_january.trip_duration.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_january.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(dataset_january.pickup_datetime)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(dataset_january.pickup_datetime)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert trip_duration from date to the total number of minutes\n",
    "dataset_january['trip_duration'] = dataset_january['trip_duration'].dt.total_seconds() / 60\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_before = dataset_january.shape[0]\n",
    "#Keep only records with trip_duration between 1 and 60 minutes\n",
    "dataset_january = dataset_january[(dataset_january.trip_duration > 1) & (dataset_january.trip_duration < 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_after = dataset_january.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46601\n"
     ]
    }
   ],
   "source": [
    "res = n_before - n_after\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.983333333333334\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(dataset_january.trip_duration.max())\n",
    "print(dataset_january.trip_duration.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. The features we'll user for our model are the pickup and dropoff location IDs.\n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\"\n",
    "\n",
    "What's the factions of missing values for the pickup location ID? (Or the fraction of \"-1\"s after you filled the NAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_january = dataset_january[['PUlocationID', 'DOlocationID', 'trip_duration']]\n",
    "dataset_january = dataset_january.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16383403866869042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print((dataset_january.shape[0] - dataset_january[dataset_january.PUlocationID == -1].shape[0]) / dataset_january.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model :\n",
    "\n",
    "- Turn the dataframe into a list of dictionaries\n",
    "- Fit a dictionary vectorizer\n",
    "- Get a feature matrix from it\n",
    "\n",
    " What's the dimensionality of this matrix? (The number of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset_january.trip_duration\n",
    "X = dataset_january.drop(columns=['trip_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset_january into a list of dictionaries\n",
    "X = X.to_dict('records')\n",
    "# Fit a dictionary vectorizer\n",
    "vectorizer = DictVectorizer(sparse = False)\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "X = one_hot_encoder.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Now let's use the feature matrix from the previous step to train a model :\n",
    "\n",
    "- Train a plain linear regression model with default parameters\n",
    "- Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Now let's apply this model to the validation dataset.\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.395031820590392\n"
     ]
    }
   ],
   "source": [
    "# Create train test split using X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Train and evaluate a linear regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred, squared = False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393601814951502\n"
     ]
    }
   ],
   "source": [
    "preds_train = regressor.predict(X_train)\n",
    "print(mean_squared_error(y_train, preds_train, squared = False))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6b992247a02372e661319281dc4c7fa14a0f2a41e9a4da052a0f51c9f6f100b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('zoomcamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
